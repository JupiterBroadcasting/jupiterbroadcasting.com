{
  "type": "episode",
  "draft": false,
  "show_slug": "linux-unplugged",
  "show_name": "LINUX Unplugged",
  "episode": 540,
  "episode_padded": "0540",
  "episode_guid": "56a10dce-2be8-433c-ad74-a2bb2442f3a9",
  "slug": "540",
  "title": "Uncensored AI on Linux",
  "description": "We test two popular methods to run local language models on your Linux box. Then, we push the limits to see which language models will toe the line and which won't.",
  "date": "2023-12-10T20:30:00-08:00",
  "header_image": "/images/shows/linux-unplugged.png",
  "categories": [
    "LINUX Unplugged"
  ],
  "tags": [
    "32-bit challenge",
    "ai executable code",
    "bail out punishment",
    "call for sessions",
    "chat ui",
    "chatgpt",
    "command line",
    "continue.dev",
    "contribution",
    "dedicated box",
    "discord bots",
    "discounts",
    "docker image",
    "egpu passthrough",
    "freebsd desktop vm",
    "gentoo",
    "high accuracy",
    "horror story",
    "hyprland",
    "it mixup",
    "jupiter broadcasting",
    "large language models",
    "linux",
    "linux podcast",
    "linux unplugged",
    "linuxfest 2024",
    "linuxfest northwest",
    "llamagpt",
    "locally hosted language model chat web app",
    "logseq",
    "marker",
    "nixified ai",
    "obsidian",
    "offline",
    "ollama",
    "ollama cli",
    "ollama library",
    "ollama manual install",
    "ollama modelfiles",
    "ollama webui",
    "ollamahub",
    "pdf to markdown",
    "phoronix",
    "power management",
    "razer core x",
    "refact.ai",
    "rss feed parsing",
    "scale trip",
    "self-hosted",
    "session buddy",
    "spaceballs",
    "speech note",
    "state of large language models",
    "tech horror story",
    "telegram bots",
    "texas linux fest 2024",
    "thunderbolt 3",
    "vscode ai plugin"
  ],
  "hosts": [
    "chris",
    "wes",
    "brent"
  ],
  "guests": [],
  "sponsors": [
    "tailscale.com-lup",
    "linode.com-lup",
    "kolide.com-lup"
  ],
  "podcast_duration": "01:20:17",
  "podcast_file": "https://aphid.fireside.fm/d/1437767933/f31a453c-fa15-491f-8618-3f71f1d565e5/56a10dce-2be8-433c-ad74-a2bb2442f3a9.mp3",
  "podcast_bytes": 67446722,
  "podcast_chapters": {
    "version": "1.1.0",
    "chapters": [
      {
        "startTime": 0,
        "title": "Intro",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 124,
        "title": "Housekeeping",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 321,
        "title": "Linux-y Llama",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 1816,
        "title": "32-Bit Challenge",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 2145,
        "title": "Reverse Dragon Naturally Speaking",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 2545,
        "title": "Convention Consternation",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 2923,
        "title": "Boosts",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 4497,
        "title": "Pick",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      },
      {
        "startTime": 4674,
        "title": "Outro",
        "img": null,
        "url": null,
        "toc": null,
        "endTime": null,
        "location": null
      }
    ],
    "author": "Jupiter Broadcasting",
    "title": "540: Uncensored AI on Linux",
    "podcastName": "LINUX Unplugged",
    "description": null,
    "fileName": null,
    "waypoints": null
  },
  "podcast_alt_file": null,
  "podcast_ogg_file": null,
  "video_file": null,
  "video_hd_file": null,
  "video_mobile_file": null,
  "youtube_link": null,
  "jb_url": null,
  "fireside_url": "/540"
}


### Episode Links

  * [üéâ Alby](https://getalby.com/ "üéâ Alby") ‚Äî Boost into the show, first grab Alby, top it off, and then head over to the Podcast Index.
  * [‚ö°Ô∏è LINUX Unplugged on the Podcastindex.org](https://podcastindex.org/podcast/575694 "‚ö°Ô∏è LINUX Unplugged on the Podcastindex.org") ‚Äî You can boost from the web. Once Alby is topped off, visit our page on the Podcast Index.
  * [Brent in Berlin Meetup](https://www.meetup.com/jupiterbroadcasting/events/297742521/ "Brent in Berlin Meetup") ‚Äî Brent is back in Berlin and we're having a LOW KEY meetup at the NixOS night at cbase.
  * [One Time Fiat Fun for SCaLE 2024](https://jupitersignal.memberful.com/checkout?plan=102844 "One Time Fiat Fun for SCaLE 2024")
  * [Southern California Linux Expo 19](https://www.socallinuxexpo.org/scale/21x "Southern California Linux Expo 19")
  * [Purchase a SCALE Pass 63](https://register.socallinuxexpo.org/reg6/ "Purchase a SCALE Pass 63")
  * [First NixCon North America!](https://discourse.nixos.org/t/announcing-first-nixcon-north-america/35874 "First NixCon North America!")
  * [NixCon North America | SCALE 21x](https://www.socallinuxexpo.org/scale/21x/nixcon-us "NixCon North America | SCALE 21x")
  * [NixCon North America Call for Proposals](https://sessionize.com/nixcon-na-2024/ "NixCon North America Call for Proposals")
  * [Texas Linux Fest 2024](https://2024.texaslinuxfest.org/ "Texas Linux Fest 2024")
  * [LFNW 2024: Ready or not](https://discuss.lfnw.org/t/lfnw2024-ready-or-not/698 "LFNW 2024: Ready or not")
  * [LFNW 2024: Call for Sessions](https://sessionize.com/lfnw2024 "LFNW 2024: Call for Sessions")
  * [Jupiter Broadcasting Live Calendar](http://jupiterbroadcasting.com/calendar "Jupiter Broadcasting Live Calendar")
  * [2023 Unplugged Tuxies](http://tuxies.party/ "2023 Unplugged Tuxies")
  * [Ollama](https://github.com/jmorganca/ollama "Ollama") ‚Äî Get up and running with Llama 2 and other large language models locally.
  * [OllamaHub](https://ollamahub.com/ "OllamaHub") ‚Äî Explore and Download Custom Ollama Modelfiles.
  * [ollama library](https://ollama.ai/library "ollama library")
  * [Ollama Manual Install](https://github.com/jmorganca/ollama/blob/main/docs/linux.md "Ollama Manual Install")
  * [Ollama Docker Image](https://hub.docker.com/r/ollama/ollama "Ollama Docker Image")
  * [ollama-webui](https://github.com/ollama-webui/ollama-webui "ollama-webui")
  * [LlamaGPT](https://github.com/getumbrel/llama-gpt "LlamaGPT")
  * [llama-gpt](https://github.com/getumbrel/llama-gpt#benchmarks "llama-gpt") ‚Äî A self-hosted, offline, ChatGPT-like chatbot. Powered by Llama 2. 100% private, with no data leaving your device. New: Code Llama support!
  * [Continue.dev](https://continue.dev/ "Continue.dev") ‚Äî An open-source autopilot in your IDE
  * [Refact.ai](https://refact.ai/ "Refact.ai") ‚Äî Refact is an open-source AI coding assistant with blazing-fast code completion, powerful code improvement tools, and chat.
  * [32-Bit Challenge Chat room](https://bit.ly/32bitchat "32-Bit Challenge Chat room")
  * [Speech Note](https://flathub.org/apps/net.mkiol.SpeechNote "Speech Note") ‚Äî Speech Note let you take, read and translate notes in multiple languages. It uses Speech to Text, Text to Speech and Machine Translation to do so. Text and voice processing take place entirely offline, locally on your computer, without using a network connection. Your privacy is always respected. No data is sent to the Internet.
  * [Speech Note on GitHub](https://github.com/mkiol/dsnote "Speech Note on GitHub")
  * [LFNW: Call for Sponsors](https://2024.lfnw.org/linuxfest-northwest-2024-sponsorship-prospectus.pdf "LFNW: Call for Sponsors")
  * [Framework 13 (Intel) NixOS Module](https://github.com/NixOS/nixos-hardware/tree/master/framework/13-inch/13th-gen-intel "Framework 13 \(Intel\) NixOS Module")
  * [GeneBean's hyprland nix config](https://github.com/genebean/dots/blob/main/modules/nixos/default.nix "GeneBean's hyprland nix config")
  * [Razer Core X - Thunderbolt‚Ñ¢ 3 eGPU](https://www.razer.com/gaming-egpus/razer-core-x "Razer Core X - Thunderbolt‚Ñ¢ 3 eGPU")
  * [CompleteNoobs: Ubuntu KVM to Windows 10 - Thinkpad T470 - Razer Core X - GTX 970 -](https://www.completenoobs.com/noobs/Ubuntu_KVM_to_Windows_10_-_Thinkpad_T470_-_Razer_Core_X_-_GTX_970 "CompleteNoobs: Ubuntu KVM to Windows 10 - Thinkpad T470 - Razer Core X - GTX 970 -")
  * [LINUX Unplugged 308: The One About GPU Passthrough](https://linuxunplugged.com/308 "LINUX Unplugged 308: The One About GPU Passthrough") ‚Äî Our crew walks you through their PCI Passthrough setups that let them run Windows, macOS, and distro-hop all from one Linux machine.
  * [Pick: Marker](https://github.com/VikParuchuri/marker "Pick: Marker") ‚Äî Convert PDF to markdown quickly with high accuracy


